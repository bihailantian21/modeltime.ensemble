% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ensemble_linear_stack.R
\name{ensemble_linear_stack}
\alias{ensemble_linear_stack}
\title{Creates a Linear Stacked Ensemble Model}
\usage{
ensemble_linear_stack(
  object,
  resamples,
  kfolds = 5,
  grid_size = 6,
  penalty_range = c(-10, 0),
  mixture_range = c(0, 1),
  control = control_resamples()
)
}
\arguments{
\item{object}{A Modeltime Table. Used for ensemble sub-models.}

\item{resamples}{An \code{rset} resample object.
Used to generate sub-model predictions for the meta-learner.
See \code{\link[timetk:time_series_cv]{timetk::time_series_cv()}} for making time series resamples.}

\item{kfolds}{Controls the number of folds used in the
meta-learner's cross-validation.}

\item{grid_size}{Controls the grid size for penalty and mixture
used in the meta-learner's cross validation.}

\item{penalty_range}{Controls the range of acceptable penalty values
on a Log Base-10 Scale. Used in the meta-learner's cross validation.}

\item{mixture_range}{Controls the range of acceptable mixtures.
Used in the meta-learner's cross validation.}

\item{control}{A \code{\link[tune:control_grid]{tune::control_resamples()}} object to provide
control over the resampling process.}
}
\description{
Uses Penalized Regression (Elastic Net) to select optimal
weights for stacking sub-models.
}
\details{
The input to an \code{ensemble_linear_stack()} model is always a Modeltime Table,
which contains the sub-models that you will ensemble.

\strong{Ensemble Process}

The Meta-Learner Ensembling Process uses the following basic steps:
\enumerate{
\item \strong{Make cross-validation predictions for each sub-model.}
The user provides the cross validation as \code{resamples}
(using a function like \code{\link[timetk:time_series_cv]{timetk::time_series_cv()}}.
The sub-model predictions are needed to made as the input for the
meta-learner.
\item \strong{Apply Penalized Regression (Meta-Learner).} The sub-model out-of-sample cross validation predictions are then
Modeled using Penalized Regresstion (Elastic Net). This process uses tuning to find an
optimal \code{penalty} and \code{mixture}. The model is then fitted to the full data set.
\item \strong{Use Coefficients as Loadings.} The penalized regression is performed without an intercept
so the coefficients returned can be used to weight the models.
}

\strong{Progress}

The best way to follow the training process and watch progress is to use
\code{control = control_resamples(verbose = TRUE)} to see progress.

\strong{Parallelize}

Portions of the process can be parallelized. To parallelize, set
up parallelization using \code{tune} via one of the backends such as
\code{doFuture}. Then set \code{control = control_resamples(allow_par = TRUE)}
}
\examples{
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(tidyverse)
library(timetk)

\dontrun{
resamples_tscv <- training(m750_splits) \%>\%
    time_series_cv(
        assess  = "2 years",
        initial = "5 years",
        skip    = "2 years",
        slice_limit = 6
    )

ensemble_fit_ls <- m750_models \%>\%
    ensemble_linear_stack(
        resamples = resamples_tscv,
        control   = control_resamples(verbose = TRUE)
    )
}

}
